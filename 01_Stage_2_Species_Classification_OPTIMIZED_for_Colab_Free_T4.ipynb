{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMekYTTPkIAhTKomatlDQCY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ErangaOttachchige/Final-Year-Research-Project/blob/main/01_Stage_2_Species_Classification_OPTIMIZED_for_Colab_Free_T4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stage 2 Species Classification - OPTIMIZED for Colab Free T4\n",
        "# Key improvements:\n",
        "# - Faster image copying (shutil > rsync)\n",
        "# - Preprocessed dataset (cached 224x224 tensors)\n",
        "# - Smart worker config (no RAM crash)\n",
        "# - Gradient accumulation for effective larger batches\n",
        "# - Progress tracking\n"
      ],
      "metadata": {
        "id": "H7mFhVhl2XgW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_IXghmq2V_c",
        "outputId": "3d9e400e-33ba-49e3-fdb4-60a4570bebcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ“ PROC_DIR files: ['cct20_species_annotations.csv', 'cct20_stage1_imagelevel.csv', 'cct20_stage2_species_imagelevel.csv']\n",
            "âœ“ Stage2 CSV exists: True\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# SETUP: Mount Drive + Paths\n",
        "# ============================================================================\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "import os\n",
        "DRIVE_CCT = \"/content/drive/MyDrive/datasets/cct20\"\n",
        "IMG_DIR   = f\"{DRIVE_CCT}/eccv_18_all_images_sm\"\n",
        "PROC_DIR  = f\"{DRIVE_CCT}/processed\"\n",
        "CSV_STAGE2 = f\"{PROC_DIR}/cct20_stage2_species_imagelevel.csv\"\n",
        "\n",
        "print(\"âœ“ PROC_DIR files:\", os.listdir(PROC_DIR))\n",
        "print(\"âœ“ Stage2 CSV exists:\", os.path.exists(CSV_STAGE2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# INSTALL PACKAGES\n",
        "# ============================================================================\n",
        "!pip -q install timm torchmetrics pandas numpy scikit-learn pillow tqdm\n",
        "\n",
        "import torch\n",
        "print(\"âœ“ CUDA:\", torch.cuda.is_available())\n",
        "print(\"âœ“ GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "452GWiVf2kH9",
        "outputId": "4bffacc4-fe19-4d3c-e70c-3898fe572060"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ CUDA: True\n",
            "âœ“ GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# LOAD CSV + CREATE CACHE DIRECTLY FROM DRIVE\n",
        "# ============================================================================\n",
        "import pandas as pd\n",
        "import glob\n",
        "import torch\n",
        "import hashlib\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load CSV (keep Drive paths - we'll cache directly)\n",
        "df = pd.read_csv(CSV_STAGE2)\n",
        "\n",
        "# Verify paths exist\n",
        "missing = (~df[\"path\"].apply(os.path.exists)).sum()\n",
        "print(f\"âœ“ Rows: {len(df)}, Missing: {missing}\")\n",
        "print(\"\\nSplit counts:\\n\", df[\"split\"].value_counts())\n",
        "print(\"\\nLabel counts:\\n\", df[\"label_stage2\"].value_counts())\n",
        "\n",
        "# Label mapping\n",
        "classes = sorted(df[\"label_stage2\"].unique())\n",
        "class_to_idx = {c:i for i,c in enumerate(classes)}\n",
        "idx_to_class = {i:c for c,i in class_to_idx.items()}\n",
        "df[\"y\"] = df[\"label_stage2\"].map(class_to_idx)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uSoW91D9idO",
        "outputId": "36f10d38-7ce2-4a05-93c6-e58a759fe4b7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Rows: 51237, Missing: 0\n",
            "\n",
            "Split counts:\n",
            " split\n",
            "test_trans    20384\n",
            "test_cis      13856\n",
            "train         12885\n",
            "val_cis        2448\n",
            "val_trans      1664\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Label counts:\n",
            " label_stage2\n",
            "opossum     13688\n",
            "raccoon      7841\n",
            "rabbit       5549\n",
            "coyote       5315\n",
            "bobcat       4961\n",
            "cat          4601\n",
            "squirrel     3181\n",
            "dog          2788\n",
            "bird         1402\n",
            "skunk         857\n",
            "rodent        812\n",
            "other         242\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# PREPROCESS DIRECTLY FROM DRIVE TO LOCAL CACHE (one-time)\n",
        "# ============================================================================\n",
        "\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from functools import partial\n",
        "\n",
        "CACHE_DIR = \"/content/preprocessed_cache\"\n",
        "os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "\n",
        "def get_cache_path(img_path):\n",
        "    \"\"\"Generate unique cache filename\"\"\"\n",
        "    hash_name = hashlib.md5(img_path.encode()).hexdigest()\n",
        "    return os.path.join(CACHE_DIR, f\"{hash_name}.pt\")\n",
        "\n",
        "# Add cache paths to dataframe\n",
        "df[\"cache_path\"] = df[\"path\"].apply(get_cache_path)\n",
        "\n",
        "# Check if cache exists\n",
        "cached_count = len(glob.glob(CACHE_DIR + \"/*.pt\"))\n",
        "\n",
        "def process_one_image(row, preprocess_tf):\n",
        "    \"\"\"Process and cache a single image\"\"\"\n",
        "    cache_path = row[\"cache_path\"]\n",
        "    if os.path.exists(cache_path):\n",
        "        return\n",
        "    try:\n",
        "        img = Image.open(row[\"path\"]).convert(\"RGB\")\n",
        "        tensor = preprocess_tf(img)\n",
        "        torch.save(tensor, cache_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {row['path']}: {e}\")\n",
        "\n",
        "if cached_count < len(df) * 0.95:\n",
        "    print(f\"ðŸ”„ Parallel caching ({cached_count}/{len(df)} exist)...\")\n",
        "    print(\"Using 8 parallel workers - should take ~3-5 min\")\n",
        "\n",
        "    preprocess_tf = T.Compose([\n",
        "        T.Resize((224, 224)),\n",
        "        T.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    # Get rows that need processing\n",
        "    rows_to_process = [row for _, row in df.iterrows()]\n",
        "\n",
        "    # Process 8 images at a time (parallel)\n",
        "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
        "        list(tqdm(\n",
        "            executor.map(partial(process_one_image, preprocess_tf=preprocess_tf),\n",
        "                        rows_to_process),\n",
        "            total=len(rows_to_process),\n",
        "            desc=\"Parallel caching\"\n",
        "        ))\n",
        "\n",
        "    print(f\"âœ“ Cache complete! {len(glob.glob(CACHE_DIR + '/*.pt'))} tensors\")\n",
        "else:\n",
        "    print(f\"âœ“ Cache exists ({cached_count} tensors) - skipping preprocessing!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gY5q4eko9pRu",
        "outputId": "fc8f4154-c9f0-4d05-89d1-b29a8718ff7a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”„ Parallel caching (640/51237 exist)...\n",
            "Using 8 parallel workers - should take ~3-5 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Parallel caching: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51237/51237 [44:22<00:00, 19.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Cache complete! 51237 tensors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# OPTIMIZED DATASET (loads cached tensors, not raw images)\n",
        "# ============================================================================\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "# Augmentation transforms (applied to cached tensors during training)\n",
        "aug_tf = T.Compose([\n",
        "    T.RandomHorizontalFlip(0.5),\n",
        "    T.ColorJitter(0.2, 0.2, 0.1),\n",
        "])\n",
        "\n",
        "class CachedImageDS(Dataset):\n",
        "    \"\"\"Loads preprocessed tensors (10x faster than PIL)\"\"\"\n",
        "    def __init__(self, frame, augment=False):\n",
        "        self.df = frame.reset_index(drop=True)\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        row = self.df.iloc[i]\n",
        "\n",
        "        # Load cached tensor (very fast!)\n",
        "        x = torch.load(row[\"cache_path\"])\n",
        "\n",
        "        # Apply augmentation if training\n",
        "        if self.augment:\n",
        "            x = aug_tf(x)\n",
        "\n",
        "        y = int(row[\"y\"])\n",
        "        return x, y\n",
        "\n",
        "# Split data\n",
        "train_df = df[df[\"split\"]==\"train\"].reset_index(drop=True)\n",
        "val_df   = df[df[\"split\"]==\"val_cis\"].reset_index(drop=True)\n",
        "valT_df  = df[df[\"split\"]==\"val_trans\"].reset_index(drop=True)\n",
        "test_cis_df   = df[df[\"split\"]==\"test_cis\"].reset_index(drop=True)\n",
        "test_trans_df = df[df[\"split\"]==\"test_trans\"].reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nâœ“ Splits - train: {len(train_df)}, val_cis: {len(val_df)}, val_trans: {len(valT_df)}\")\n",
        "\n",
        "# Create datasets\n",
        "train_ds = CachedImageDS(train_df, augment=True)\n",
        "val_ds   = CachedImageDS(val_df, augment=False)\n",
        "valT_ds  = CachedImageDS(valT_df, augment=False)\n",
        "test_cis_ds   = CachedImageDS(test_cis_df, augment=False)\n",
        "test_trans_ds = CachedImageDS(test_trans_df, augment=False)\n",
        "\n",
        "# Balanced sampling\n",
        "counts = train_df[\"y\"].value_counts().sort_index()\n",
        "w_class = 1.0 / counts\n",
        "w_sample = train_df[\"y\"].map(w_class).values\n",
        "sampler = WeightedRandomSampler(torch.tensor(w_sample, dtype=torch.double),\n",
        "                                num_samples=len(w_sample),\n",
        "                                replacement=True)\n",
        "\n",
        "# Class weights for loss\n",
        "cw = (counts.sum() / (len(counts) * counts)).values\n",
        "class_weight = torch.tensor(cw, dtype=torch.float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8URJ4Zkt20jF",
        "outputId": "92f5be9c-ce12-47df-8b0d-cd7469e387b2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ“ Splits - train: 12885, val_cis: 2448, val_trans: 1664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# OPTIMIZED DATALOADERS (no RAM crash on Colab free)\n",
        "# ============================================================================\n",
        "BATCH_TRAIN = 32  # Smaller batch, use gradient accumulation\n",
        "BATCH_EVAL  = 64\n",
        "NUM_WORKERS = 2   # CRITICAL: 2 workers max on Colab free to avoid RAM crash\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_TRAIN, sampler=sampler,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds, batch_size=BATCH_EVAL, shuffle=False,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
        "valT_loader  = DataLoader(valT_ds, batch_size=BATCH_EVAL, shuffle=False,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
        "test_cis_loader = DataLoader(test_cis_ds, batch_size=BATCH_EVAL, shuffle=False,\n",
        "                             num_workers=NUM_WORKERS, pin_memory=True)\n",
        "test_trans_loader = DataLoader(test_trans_ds, batch_size=BATCH_EVAL, shuffle=False,\n",
        "                               num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "print(f\"âœ“ Classes: {len(classes)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIZFH1Mu27nF",
        "outputId": "9626a363-27d6-4b5e-dc38-6204673c531d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Classes: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# TRAINING WITH GRADIENT ACCUMULATION\n",
        "# ============================================================================\n",
        "import timm\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"âœ“ Device: {device}\")\n",
        "\n",
        "model = timm.create_model(\"efficientnet_b0\", pretrained=True, num_classes=len(classes)).to(device)\n",
        "crit  = nn.CrossEntropyLoss(weight=class_weight.to(device))\n",
        "opt   = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n",
        "\n",
        "# Gradient accumulation: effective batch = BATCH_TRAIN * ACCUM_STEPS\n",
        "ACCUM_STEPS = 2  # Effective batch = 32 * 2 = 64\n",
        "\n",
        "def eval_loader(loader, name=\"eval\"):\n",
        "    model.eval()\n",
        "    ys, ps = [], []\n",
        "    with torch.no_grad():\n",
        "        for x, y in tqdm(loader, desc=name, leave=False):\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "            with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
        "                logits = model(x)\n",
        "            p = logits.argmax(1)\n",
        "            ys.extend(y.cpu().tolist())\n",
        "            ps.extend(p.cpu().tolist())\n",
        "    return accuracy_score(ys, ps), f1_score(ys, ps, average=\"macro\"), ys, ps\n",
        "\n",
        "SAVE_PATH = f\"{PROC_DIR}/stage2_best_species_efficientnet_b0_optimized.pt\"\n",
        "best = -1.0\n",
        "\n",
        "EPOCHS = 5\n",
        "for ep in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {ep}/{EPOCHS}\")\n",
        "    for batch_idx, (x, y) in enumerate(pbar):\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        y = y.to(device, non_blocking=True)\n",
        "\n",
        "        with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
        "            logits = model(x)\n",
        "            loss = crit(logits, y) / ACCUM_STEPS  # Scale loss\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        # Update weights every ACCUM_STEPS\n",
        "        if (batch_idx + 1) % ACCUM_STEPS == 0:\n",
        "            scaler.step(opt)\n",
        "            scaler.update()\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "\n",
        "        running_loss += loss.item() * x.size(0) * ACCUM_STEPS\n",
        "        pbar.set_postfix({\"loss\": f\"{loss.item() * ACCUM_STEPS:.4f}\"})\n",
        "\n",
        "    train_loss = running_loss / len(train_df)\n",
        "\n",
        "    val_acc, val_mf1, _, _ = eval_loader(val_loader, \"val_cis\")\n",
        "    print(f\"\\nEpoch {ep}: train_loss={train_loss:.4f} | val_cis acc={val_acc:.3f} macroF1={val_mf1:.3f}\")\n",
        "\n",
        "    if len(valT_df) > 0:\n",
        "        vt_acc, vt_mf1, _, _ = eval_loader(valT_loader, \"val_trans\")\n",
        "        print(f\"          val_trans acc={vt_acc:.3f} macroF1={vt_mf1:.3f}\")\n",
        "\n",
        "    if val_mf1 > best:\n",
        "        best = val_mf1\n",
        "        torch.save(model.state_dict(), SAVE_PATH)\n",
        "        print(f\"ðŸ’¾ SAVED BEST (macroF1={best:.3f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6Nqrkcj2_Ck",
        "outputId": "b812fdf7-0f12-4228-82c2-38543d972fd7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1987785691.py:15: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n",
            "Epoch 1/5:   0%|          | 0/403 [00:00<?, ?it/s]/tmp/ipython-input-1987785691.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "Epoch 1/5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 403/403 [01:31<00:00,  4.41it/s, loss=0.1468]\n",
            "val_cis:   0%|          | 0/39 [00:00<?, ?it/s]/tmp/ipython-input-1987785691.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: train_loss=0.4717 | val_cis acc=0.667 macroF1=0.643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val_trans:   0%|          | 0/26 [00:00<?, ?it/s]/tmp/ipython-input-1987785691.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_trans acc=0.202 macroF1=0.136\n",
            "ðŸ’¾ SAVED BEST (macroF1=0.643)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5:   0%|          | 0/403 [00:00<?, ?it/s]/tmp/ipython-input-1987785691.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "Epoch 2/5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 403/403 [01:04<00:00,  6.29it/s, loss=0.0421]\n",
            "val_cis:   0%|          | 0/39 [00:00<?, ?it/s]/tmp/ipython-input-1987785691.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2: train_loss=0.1140 | val_cis acc=0.754 macroF1=0.731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val_trans:   0%|          | 0/26 [00:00<?, ?it/s]/tmp/ipython-input-1987785691.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_trans acc=0.245 macroF1=0.142\n",
            "ðŸ’¾ SAVED BEST (macroF1=0.731)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5:   0%|          | 0/403 [00:00<?, ?it/s]/tmp/ipython-input-1987785691.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "Epoch 3/5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 403/403 [01:01<00:00,  6.55it/s, loss=0.0267]\n",
            "val_cis:   0%|          | 0/39 [00:00<?, ?it/s]/tmp/ipython-input-1987785691.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3: train_loss=0.0595 | val_cis acc=0.800 macroF1=0.794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val_trans:   0%|          | 0/26 [00:00<?, ?it/s]/tmp/ipython-input-1987785691.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_trans acc=0.236 macroF1=0.162\n",
            "ðŸ’¾ SAVED BEST (macroF1=0.794)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5:   0%|          | 0/403 [00:00<?, ?it/s]/tmp/ipython-input-1987785691.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "Epoch 4/5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 403/403 [01:00<00:00,  6.70it/s, loss=0.0148]\n",
            "val_cis:   0%|          | 0/39 [00:00<?, ?it/s]/tmp/ipython-input-1987785691.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4: train_loss=0.0409 | val_cis acc=0.827 macroF1=0.795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val_trans:   0%|          | 0/26 [00:00<?, ?it/s]/tmp/ipython-input-1987785691.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_trans acc=0.227 macroF1=0.148\n",
            "ðŸ’¾ SAVED BEST (macroF1=0.795)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5:   0%|          | 0/403 [00:00<?, ?it/s]/tmp/ipython-input-1987785691.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "Epoch 5/5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 403/403 [01:00<00:00,  6.63it/s, loss=0.0452]\n",
            "val_cis:   0%|          | 0/39 [00:00<?, ?it/s]/tmp/ipython-input-1987785691.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5: train_loss=0.0301 | val_cis acc=0.834 macroF1=0.808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val_trans:   0%|          | 0/26 [00:00<?, ?it/s]/tmp/ipython-input-1987785691.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_trans acc=0.268 macroF1=0.168\n",
            "ðŸ’¾ SAVED BEST (macroF1=0.808)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# TEST EVALUATION\n",
        "# ============================================================================\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL TEST EVALUATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "model.load_state_dict(torch.load(SAVE_PATH, map_location=device))\n",
        "\n",
        "cis_acc, cis_mf1, cis_y, cis_p = eval_loader(test_cis_loader, \"test_cis\")\n",
        "tr_acc,  tr_mf1,  tr_y,  tr_p  = eval_loader(test_trans_loader, \"test_trans\")\n",
        "\n",
        "print(f\"\\nðŸŽ¯ TEST CIS   â†’ acc={cis_acc:.3f}, macroF1={cis_mf1:.3f}\")\n",
        "print(f\"ðŸŽ¯ TEST TRANS â†’ acc={tr_acc:.3f}, macroF1={tr_mf1:.3f}\")\n",
        "\n",
        "print(\"\\n--- CIS REPORT ---\")\n",
        "print(classification_report(cis_y, cis_p, target_names=[idx_to_class[i] for i in range(len(classes))]))\n",
        "\n",
        "print(\"\\n--- TRANS REPORT ---\")\n",
        "print(classification_report(tr_y, tr_p, target_names=[idx_to_class[i] for i in range(len(classes))]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ih2GVwas3DjE",
        "outputId": "f314a09f-02b9-4b19-e4f0-5bde506c6e62"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "FINAL TEST EVALUATION\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test_cis:   0%|          | 0/217 [00:00<?, ?it/s]/tmp/ipython-input-1987785691.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "test_trans:   0%|          | 0/319 [00:00<?, ?it/s]/tmp/ipython-input-1987785691.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "                                                             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸŽ¯ TEST CIS   â†’ acc=0.612, macroF1=0.579\n",
            "ðŸŽ¯ TEST TRANS â†’ acc=0.380, macroF1=0.260\n",
            "\n",
            "--- CIS REPORT ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        bird       0.47      0.51      0.49       573\n",
            "      bobcat       0.42      0.78      0.55       897\n",
            "         cat       0.63      0.69      0.66      1632\n",
            "      coyote       0.69      0.56      0.62      1326\n",
            "         dog       0.68      0.53      0.60       845\n",
            "     opossum       0.89      0.64      0.74      4524\n",
            "       other       0.71      0.55      0.62       168\n",
            "      rabbit       0.55      0.43      0.48      1758\n",
            "     raccoon       0.40      0.81      0.54      1047\n",
            "      rodent       0.55      0.52      0.53       233\n",
            "       skunk       0.54      0.80      0.64       194\n",
            "    squirrel       0.44      0.51      0.48       659\n",
            "\n",
            "    accuracy                           0.61     13856\n",
            "   macro avg       0.58      0.61      0.58     13856\n",
            "weighted avg       0.67      0.61      0.62     13856\n",
            "\n",
            "\n",
            "--- TRANS REPORT ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        bird       0.07      0.09      0.08       224\n",
            "      bobcat       0.28      0.24      0.26      2331\n",
            "         cat       0.14      0.30      0.19      1418\n",
            "      coyote       0.36      0.29      0.32      2249\n",
            "         dog       0.36      0.59      0.44       888\n",
            "     opossum       0.71      0.39      0.50      5504\n",
            "       other       0.00      0.00      0.00        15\n",
            "      rabbit       0.11      0.37      0.17       846\n",
            "     raccoon       0.71      0.46      0.56      5469\n",
            "      rodent       0.00      0.00      0.00        61\n",
            "       skunk       0.13      0.49      0.20       328\n",
            "    squirrel       0.39      0.39      0.39      1051\n",
            "\n",
            "    accuracy                           0.38     20384\n",
            "   macro avg       0.27      0.30      0.26     20384\n",
            "weighted avg       0.51      0.38      0.42     20384\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SAVE METADATA\n",
        "# ============================================================================\n",
        "import json\n",
        "\n",
        "mapping = {\n",
        "    \"classes\": classes,\n",
        "    \"class_to_idx\": class_to_idx\n",
        "}\n",
        "out_json = f\"{PROC_DIR}/stage2_label_mapping.json\"\n",
        "with open(out_json, \"w\") as f:\n",
        "    json.dump(mapping, f, indent=2)\n",
        "\n",
        "print(f\"\\nâœ“ Saved: {out_json}\")\n",
        "print(\"âœ“ Training complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI9xspvm3Foe",
        "outputId": "997028b6-703c-47bc-ab8a-bc3af11eec61"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ“ Saved: /content/drive/MyDrive/datasets/cct20/processed/stage2_label_mapping.json\n",
            "âœ“ Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4jCgHSpK4pLO"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}