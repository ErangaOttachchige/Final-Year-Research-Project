{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMonPrnjfO6kaDPD4yjTfnj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ErangaOttachchige/Final-Year-Research-Project/blob/main/02_stage1_detection_filter_training_OPTIMIZED_for_Colab_Free_T4_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObnwXvUF7OSk",
        "outputId": "d6249687-0a20-4aea-d261-f1212aecf633"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Processed: ['cct20_species_annotations.csv', 'cct20_stage1_imagelevel.csv', 'cct20_stage2_species_imagelevel.csv', 'stage2_best_species_efficientnet_b0_optimized.pt', 'stage2_label_mapping.json']\n"
          ]
        }
      ],
      "source": [
        "# Mount Drive + paths\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "import os\n",
        "DRIVE_CCT = \"/content/drive/MyDrive/datasets/cct20\"\n",
        "PROC_DIR = f\"{DRIVE_CCT}/processed\"\n",
        "IMG_DIR  = f\"{DRIVE_CCT}/eccv_18_all_images_sm\"\n",
        "print(\"Processed:\", os.listdir(PROC_DIR))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install packages (once per runtime)\n",
        "!pip -q install timm torchmetrics pandas numpy scikit-learn pillow tqdm\n"
      ],
      "metadata": {
        "id": "lyIrJoMo7lvd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn on GPU (in runtime settings) and check\n",
        "import torch\n",
        "print(\"CUDA:\", torch.cuda.is_available())\n",
        "print(\"GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F450r_Ci7uo0",
        "outputId": "7dac6c46-50af-44e3-eb45-100e0d54e3c1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA: False\n",
            "GPU: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df1 = pd.read_csv(\"/content/drive/MyDrive/datasets/cct20/processed/cct20_stage1_imagelevel.csv\")\n",
        "print(df1[\"label_stage1\"].value_counts())\n",
        "print(df1[\"split\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYCHXUn-IBlu",
        "outputId": "ddcc95b3-89d2-495c-eff1-1cc4e03d03d9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label_stage1\n",
            "animal    51237\n",
            "empty      4014\n",
            "car        2613\n",
            "Name: count, dtype: int64\n",
            "split\n",
            "test_trans    23275\n",
            "test_cis      15827\n",
            "train         13553\n",
            "val_cis        3484\n",
            "val_trans      1725\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Drive + paths + check files\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "import os\n",
        "DRIVE_CCT = \"/content/drive/MyDrive/datasets/cct20\"\n",
        "PROC_DIR  = f\"{DRIVE_CCT}/processed\"\n",
        "CSV_STAGE1 = f\"{PROC_DIR}/cct20_stage1_imagelevel.csv\"\n",
        "\n",
        "print(\"âœ“ PROC_DIR files:\", os.listdir(PROC_DIR))\n",
        "print(\"âœ“ Stage1 CSV exists:\", os.path.exists(CSV_STAGE1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lphwn3ZzICS7",
        "outputId": "f7aab6e5-f974-4850-8935-1f00836ee054"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ“ PROC_DIR files: ['cct20_species_annotations.csv', 'cct20_stage1_imagelevel.csv', 'cct20_stage2_species_imagelevel.csv', 'stage2_best_species_efficientnet_b0_optimized.pt', 'stage2_label_mapping.json']\n",
            "âœ“ Stage1 CSV exists: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install + check GPU\n",
        "\n",
        "!pip -q install timm torchmetrics pandas numpy scikit-learn pillow tqdm\n",
        "\n",
        "import torch\n",
        "print(\"âœ“ CUDA:\", torch.cuda.is_available())\n",
        "print(\"âœ“ GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")\n"
      ],
      "metadata": {
        "id": "_7enGBT2MUQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV + sanity checks\n",
        "import pandas as pd, os\n",
        "\n",
        "df = pd.read_csv(CSV_STAGE1)\n",
        "\n",
        "missing = (~df[\"path\"].apply(os.path.exists)).sum()\n",
        "print(f\"âœ“ Rows: {len(df)}, Missing paths: {missing}\")\n",
        "print(\"\\nSplit counts:\\n\", df[\"split\"].value_counts())\n",
        "print(\"\\nLabel counts:\\n\", df[\"label_stage1\"].value_counts())\n",
        "\n",
        "# Label mapping\n",
        "classes = [\"empty\", \"animal\", \"car\"]  # fixed order\n",
        "class_to_idx = {c:i for i,c in enumerate(classes)}\n",
        "idx_to_class = {i:c for c,i in class_to_idx.items()}\n",
        "df[\"y\"] = df[\"label_stage1\"].map(class_to_idx)\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "8p6RZhmgMXZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OPTIONAL speed boost (recommended): cache resized tensors locally\n",
        "\n",
        "# This avoids slow Drive reads and prevents crashes.\n",
        "import os, glob, hashlib\n",
        "import torch\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from functools import partial\n",
        "\n",
        "CACHE_DIR = \"/content/stage1_cache_224\"\n",
        "os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "\n",
        "def cache_path(img_path):\n",
        "    return os.path.join(CACHE_DIR, hashlib.md5(img_path.encode()).hexdigest() + \".pt\")\n",
        "\n",
        "df[\"cache_path\"] = df[\"path\"].apply(cache_path)\n",
        "\n",
        "cached = len(glob.glob(CACHE_DIR + \"/*.pt\"))\n",
        "print(\"Cached tensors now:\", cached, \" / \", len(df))\n",
        "\n",
        "pre_tf = T.Compose([\n",
        "    T.Resize((224,224)),\n",
        "    T.ToTensor(),\n",
        "])\n",
        "\n",
        "def process_one(row):\n",
        "    cp = row[\"cache_path\"]\n",
        "    if os.path.exists(cp):\n",
        "        return\n",
        "    try:\n",
        "        img = Image.open(row[\"path\"]).convert(\"RGB\")\n",
        "        x = pre_tf(img)\n",
        "        torch.save(x, cp)\n",
        "    except Exception as e:\n",
        "        # print and skip bad files\n",
        "        print(\"Error:\", row[\"path\"], e)\n",
        "\n",
        "if cached < len(df)*0.95:\n",
        "    print(\"ðŸ”„ Caching tensors locally (one-time per session)...\")\n",
        "    rows = [r for _, r in df.iterrows()]\n",
        "    with ThreadPoolExecutor(max_workers=8) as ex:\n",
        "        list(tqdm(ex.map(process_one, rows), total=len(rows), desc=\"Caching Stage1\"))\n",
        "    print(\"âœ“ Cache done:\", len(glob.glob(CACHE_DIR + \"/*.pt\")))\n",
        "else:\n",
        "    print(\"âœ“ Cache already exists â€” skipping\")\n"
      ],
      "metadata": {
        "id": "cI__zbHyNFub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset + Dataloaders (balanced sampling + stable)\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import torchvision.transforms as T\n",
        "import torch\n",
        "\n",
        "# splits\n",
        "train_df = df[df[\"split\"]==\"train\"].reset_index(drop=True)\n",
        "val_df   = df[df[\"split\"]==\"val_cis\"].reset_index(drop=True)\n",
        "valT_df  = df[df[\"split\"]==\"val_trans\"].reset_index(drop=True)\n",
        "test_cis_df   = df[df[\"split\"]==\"test_cis\"].reset_index(drop=True)\n",
        "test_trans_df = df[df[\"split\"]==\"test_trans\"].reset_index(drop=True)\n",
        "\n",
        "print(\"train:\", len(train_df), \"val_cis:\", len(val_df), \"val_trans:\", len(valT_df),\n",
        "      \"test_cis:\", len(test_cis_df), \"test_trans:\", len(test_trans_df))\n",
        "\n",
        "# augment on cached tensors (works)\n",
        "aug_tf = T.Compose([\n",
        "    T.RandomHorizontalFlip(0.5),\n",
        "    T.ColorJitter(0.2, 0.2, 0.1),\n",
        "])\n",
        "\n",
        "class CachedDS(Dataset):\n",
        "    def __init__(self, frame, augment=False):\n",
        "        self.df = frame.reset_index(drop=True)\n",
        "        self.augment = augment\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        r = self.df.iloc[i]\n",
        "        x = torch.load(r[\"cache_path\"])          # fast\n",
        "        if self.augment:\n",
        "            x = aug_tf(x)\n",
        "        y = int(r[\"y\"])\n",
        "        return x, y\n",
        "\n",
        "train_ds = CachedDS(train_df, augment=True)\n",
        "val_ds   = CachedDS(val_df, augment=False)\n",
        "valT_ds  = CachedDS(valT_df, augment=False)\n",
        "test_cis_ds   = CachedDS(test_cis_df, augment=False)\n",
        "test_trans_ds = CachedDS(test_trans_df, augment=False)\n",
        "\n",
        "# balanced sampling on train\n",
        "counts = train_df[\"y\"].value_counts().sort_index()\n",
        "w_class = 1.0 / counts\n",
        "w_sample = train_df[\"y\"].map(w_class).values\n",
        "sampler = WeightedRandomSampler(torch.tensor(w_sample, dtype=torch.double),\n",
        "                                num_samples=len(w_sample), replacement=True)\n",
        "\n",
        "# class weights (loss)\n",
        "cw = (counts.sum() / (len(counts) * counts)).values\n",
        "class_weight = torch.tensor(cw, dtype=torch.float32)\n",
        "\n",
        "print(\"Train class counts:\\n\", counts)\n",
        "print(\"Loss class weights:\\n\", class_weight)\n",
        "\n",
        "# loaders\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "NUM_WORKERS = 2 if device==\"cuda\" else 0\n",
        "PIN = True if device==\"cuda\" else False\n",
        "\n",
        "BATCH_TRAIN = 32\n",
        "BATCH_EVAL  = 64\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_TRAIN, sampler=sampler,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=PIN)\n",
        "val_loader   = DataLoader(val_ds, batch_size=BATCH_EVAL, shuffle=False,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=PIN)\n",
        "valT_loader  = DataLoader(valT_ds, batch_size=BATCH_EVAL, shuffle=False,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=PIN)\n",
        "test_cis_loader   = DataLoader(test_cis_ds, batch_size=BATCH_EVAL, shuffle=False,\n",
        "                               num_workers=NUM_WORKERS, pin_memory=PIN)\n",
        "test_trans_loader = DataLoader(test_trans_ds, batch_size=BATCH_EVAL, shuffle=False,\n",
        "                               num_workers=NUM_WORKERS, pin_memory=PIN)\n"
      ],
      "metadata": {
        "id": "R8IG1GLLNFl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train EfficientNet-B0 (AMP + accumulation + saves best)\n",
        "import timm\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"âœ“ Device:\", device)\n",
        "\n",
        "model = timm.create_model(\"efficientnet_b0\", pretrained=True, num_classes=len(classes)).to(device)\n",
        "crit  = nn.CrossEntropyLoss(weight=class_weight.to(device))\n",
        "opt   = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n",
        "\n",
        "ACCUM_STEPS = 2   # effective batch = 32 * 2 = 64\n",
        "\n",
        "def eval_loader(loader, name=\"eval\"):\n",
        "    model.eval()\n",
        "    ys, ps = [], []\n",
        "    with torch.no_grad():\n",
        "        for x,y in tqdm(loader, desc=name, leave=True):\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "            with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
        "                logits = model(x)\n",
        "            p = logits.argmax(1)\n",
        "            ys.extend(y.cpu().tolist())\n",
        "            ps.extend(p.cpu().tolist())\n",
        "    acc = accuracy_score(ys, ps)\n",
        "    mf1 = f1_score(ys, ps, average=\"macro\")\n",
        "    return acc, mf1, ys, ps\n",
        "\n",
        "SAVE_PATH = f\"{PROC_DIR}/stage1_best_empty_animal_car.pt\"\n",
        "best = -1\n",
        "\n",
        "EPOCHS = 5\n",
        "for ep in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    opt.zero_grad(set_to_none=True)\n",
        "    running = 0.0\n",
        "\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {ep}/{EPOCHS} [train]\", leave=True)\n",
        "    for i, (x,y) in enumerate(pbar, 1):\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        y = y.to(device, non_blocking=True)\n",
        "\n",
        "        with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
        "            logits = model(x)\n",
        "            loss = crit(logits, y) / ACCUM_STEPS\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        if i % ACCUM_STEPS == 0:\n",
        "            scaler.step(opt)\n",
        "            scaler.update()\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "\n",
        "        running += loss.item() * x.size(0) * ACCUM_STEPS\n",
        "        pbar.set_postfix({\"loss\": float(loss.item()*ACCUM_STEPS)})\n",
        "\n",
        "    train_loss = running / len(train_df)\n",
        "\n",
        "    val_acc, val_mf1, _, _ = eval_loader(val_loader, \"val_cis\")\n",
        "    print(f\"\\nEpoch {ep}: train_loss={train_loss:.4f} | val_cis acc={val_acc:.3f} macroF1={val_mf1:.3f}\")\n",
        "\n",
        "    if len(valT_df) > 0:\n",
        "        vt_acc, vt_mf1, _, _ = eval_loader(valT_loader, \"val_trans\")\n",
        "        print(f\"          val_trans acc={vt_acc:.3f} macroF1={vt_mf1:.3f}\")\n",
        "\n",
        "    if val_mf1 > best:\n",
        "        best = val_mf1\n",
        "        torch.save(model.state_dict(), SAVE_PATH)\n",
        "        print(f\"ðŸ’¾ SAVED BEST: {SAVE_PATH} (macroF1={best:.3f})\")\n"
      ],
      "metadata": {
        "id": "r0xxhpm6NFf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final evaluation on CIS test + TRANS test\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL TEST EVALUATION (Stage 1)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "model.load_state_dict(torch.load(SAVE_PATH, map_location=device))\n",
        "\n",
        "cis_acc, cis_mf1, cis_y, cis_p = eval_loader(test_cis_loader, \"test_cis\")\n",
        "tr_acc,  tr_mf1,  tr_y,  tr_p  = eval_loader(test_trans_loader, \"test_trans\")\n",
        "\n",
        "print(f\"\\nðŸŽ¯ TEST CIS   â†’ acc={cis_acc:.3f}, macroF1={cis_mf1:.3f}\")\n",
        "print(f\"ðŸŽ¯ TEST TRANS â†’ acc={tr_acc:.3f}, macroF1={tr_mf1:.3f}\")\n",
        "\n",
        "print(\"\\n--- CIS REPORT ---\")\n",
        "print(classification_report(cis_y, cis_p, target_names=[idx_to_class[i] for i in range(len(classes))]))\n",
        "\n",
        "print(\"\\n--- TRANS REPORT ---\")\n",
        "print(classification_report(tr_y, tr_p, target_names=[idx_to_class[i] for i in range(len(classes))]))\n"
      ],
      "metadata": {
        "id": "sG6VzuulNFZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save label mapping (for inference pipeline)\n",
        "import json\n",
        "\n",
        "mapping = {\n",
        "    \"classes\": classes,\n",
        "    \"class_to_idx\": class_to_idx\n",
        "}\n",
        "out_json = f\"{PROC_DIR}/stage1_label_mapping.json\"\n",
        "with open(out_json, \"w\") as f:\n",
        "    json.dump(mapping, f, indent=2)\n",
        "\n",
        "print(\"âœ“ Saved:\", out_json)\n",
        "print(\"âœ“ Stage 1 done!\")\n"
      ],
      "metadata": {
        "id": "97LaBikXNFQv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}