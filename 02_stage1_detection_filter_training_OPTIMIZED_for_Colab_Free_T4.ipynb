{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO/vvAIstg0RwmM9FNaLG40",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ErangaOttachchige/Final-Year-Research-Project/blob/main/02_stage1_detection_filter_training_OPTIMIZED_for_Colab_Free_T4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stage 1 Binary Filter:\n",
        "\n",
        "Label: animal vs non_animal (where non_animal = empty + car)\n",
        "\n",
        "Fast: uses your tensor cache (no local copy, no Drive rsync)\n",
        "\n",
        "Stable: low RAM, no crashes\n",
        "\n",
        "Saves to Drive: model + label mapping\n",
        "\n",
        "Progress bars: train/val/test"
      ],
      "metadata": {
        "id": "Pk1LKCtzwDhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Drive + paths\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "import os\n",
        "DRIVE_CCT = \"/content/drive/MyDrive/datasets/cct20\"\n",
        "PROC_DIR  = f\"{DRIVE_CCT}/processed\"\n",
        "CSV_STAGE1 = f\"{PROC_DIR}/cct20_stage1_imagelevel.csv\"\n",
        "\n",
        "print(\"âœ“ PROC_DIR files:\", os.listdir(PROC_DIR))\n",
        "print(\"âœ“ Stage1 CSV exists:\", os.path.exists(CSV_STAGE1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ASBJIXTRCU5",
        "outputId": "6802038a-7253-4d44-ae37-143102492c85"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ“ PROC_DIR files: ['cct20_species_annotations.csv', 'cct20_stage1_imagelevel.csv', 'cct20_stage2_species_imagelevel.csv', 'stage2_best_species_efficientnet_b0_optimized.pt', 'stage2_label_mapping.json', 'stage1_best_efficientnet_b0.pt', 'stage1_label_mapping.json', 'stage1_best_binary_efficientnet_b0.pt', 'stage1_binary_label_mapping.json']\n",
            "âœ“ Stage1 CSV exists: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install packages + check GPU\n",
        "!pip -q install timm torchmetrics pandas numpy scikit-learn pillow tqdm\n",
        "\n",
        "import torch\n",
        "print(\"âœ“ CUDA:\", torch.cuda.is_available())\n",
        "print(\"âœ“ GPU :\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fu01OM00u-Nq",
        "outputId": "71983393-8231-4c24-9e49-947b8b91fbeb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ CUDA: True\n",
            "âœ“ GPU : Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Stage1 CSV + create binary labels\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "df = pd.read_csv(CSV_STAGE1)\n",
        "\n",
        "# Binary label:\n",
        "# animal stays animal\n",
        "# car + empty become non_animal\n",
        "df[\"label_bin\"] = df[\"label_stage1\"].apply(lambda x: \"animal\" if x==\"animal\" else \"non_animal\")\n",
        "\n",
        "missing = (~df[\"path\"].apply(os.path.exists)).sum()\n",
        "print(f\"âœ“ Rows: {len(df)}, Missing paths: {missing}\")\n",
        "print(\"\\nSplit counts:\\n\", df[\"split\"].value_counts())\n",
        "print(\"\\nBinary label counts:\\n\", df[\"label_bin\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uOToepCu-K6",
        "outputId": "10b64e5b-5a73-4528-fdc4-a4d3988df202"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Rows: 57864, Missing paths: 0\n",
            "\n",
            "Split counts:\n",
            " split\n",
            "test_trans    23275\n",
            "test_cis      15827\n",
            "train         13553\n",
            "val_cis        3484\n",
            "val_trans      1725\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Binary label counts:\n",
            " label_bin\n",
            "animal        51237\n",
            "non_animal     6627\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# FIX: Re-stratify splits to ensure empty/car/animal in ALL splits\n",
        "# ============================================================================\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"FIXING DATA SPLIT - Ensuring balanced animal/car/empty\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Check current distribution by original label\n",
        "print(\"\\nCURRENT train distribution by 3-class label:\")\n",
        "current_train = df[df[\"split\"] == \"train\"]\n",
        "print(current_train[\"label_stage1\"].value_counts())\n",
        "\n",
        "# Check if empty is severely underrepresented\n",
        "empty_count = (current_train[\"label_stage1\"] == \"empty\").sum()\n",
        "car_count = (current_train[\"label_stage1\"] == \"car\").sum()\n",
        "animal_count = (current_train[\"label_stage1\"] == \"animal\").sum()\n",
        "\n",
        "print(f\"\\nTrain counts: animal={animal_count}, car={car_count}, empty={empty_count}\")\n",
        "\n",
        "# If empty is < 5% of non_animal OR < 50 samples total, re-stratify\n",
        "if empty_count < 50 or empty_count < (car_count * 0.05):\n",
        "    print(\"\\nâš ï¸ Empty severely underrepresented! Re-stratifying splits...\\n\")\n",
        "\n",
        "    # Separate by split type (keep test sets as-is, only re-split train/val)\n",
        "    test_cis = df[df[\"split\"] == \"test_cis\"].copy()\n",
        "    test_trans = df[df[\"split\"] == \"test_trans\"].copy()\n",
        "\n",
        "    # Pool together current train + val for re-splitting\n",
        "    trainable = df[df[\"split\"].isin([\"train\", \"val_cis\", \"val_trans\"])].copy()\n",
        "\n",
        "    print(f\"Pooling {len(trainable)} samples for re-split (keeping {len(test_cis)+len(test_trans)} test samples)\")\n",
        "    print(\"\\nPooled distribution by label:\")\n",
        "    print(trainable[\"label_stage1\"].value_counts())\n",
        "\n",
        "    # Stratified split: 70% train, 15% val_cis, 15% val_trans\n",
        "    # First split: 70% train, 30% val\n",
        "    train_idx, val_idx = train_test_split(\n",
        "        trainable.index,\n",
        "        test_size=0.30,\n",
        "        stratify=trainable[\"label_stage1\"],\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Second split: split val into val_cis (50%) and val_trans (50%)\n",
        "    val_subset = trainable.loc[val_idx]\n",
        "    val_cis_idx, val_trans_idx = train_test_split(\n",
        "        val_subset.index,\n",
        "        test_size=0.50,\n",
        "        stratify=val_subset[\"label_stage1\"],\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Assign new splits\n",
        "    df.loc[train_idx, \"split\"] = \"train\"\n",
        "    df.loc[val_cis_idx, \"split\"] = \"val_cis\"\n",
        "    df.loc[val_trans_idx, \"split\"] = \"val_trans\"\n",
        "\n",
        "    # Verify new distribution\n",
        "    print(\"\\nâœ“ NEW train distribution:\")\n",
        "    new_train = df[df[\"split\"] == \"train\"]\n",
        "    print(new_train[\"label_stage1\"].value_counts())\n",
        "\n",
        "    print(\"\\nâœ“ NEW val_cis distribution:\")\n",
        "    print(df[df[\"split\"] == \"val_cis\"][\"label_stage1\"].value_counts())\n",
        "\n",
        "    print(\"\\nâœ“ NEW val_trans distribution:\")\n",
        "    print(df[df[\"split\"] == \"val_trans\"][\"label_stage1\"].value_counts())\n",
        "\n",
        "    # Save fixed CSV back to Drive\n",
        "    fixed_csv = f\"{PROC_DIR}/cct20_stage1_imagelevel_FIXED.csv\"\n",
        "    df.to_csv(fixed_csv, index=False)\n",
        "    print(f\"\\nðŸ’¾ Saved fixed CSV to: {fixed_csv}\")\n",
        "    print(\"   (Original CSV unchanged)\")\n",
        "\n",
        "else:\n",
        "    print(f\"\\nâœ“ Split is OK - empty count ({empty_count}) is sufficient\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL SPLIT COUNTS:\")\n",
        "print(\"=\"*60)\n",
        "print(df[\"split\"].value_counts())\n",
        "print(\"\\nBinary labels:\")\n",
        "df[\"label_bin\"] = df[\"label_stage1\"].apply(lambda x: \"animal\" if x==\"animal\" else \"non_animal\")\n",
        "print(df[\"label_bin\"].value_counts())"
      ],
      "metadata": {
        "id": "eVu85HYcOZYA",
        "outputId": "331ae8bc-67d0-4c7b-c05b-bece1b3c91a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "FIXING DATA SPLIT - Ensuring balanced animal/car/empty\n",
            "============================================================\n",
            "\n",
            "CURRENT train distribution by 3-class label:\n",
            "label_stage1\n",
            "animal    11898\n",
            "empty       739\n",
            "car         496\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Train counts: animal=11898, car=496, empty=739\n",
            "\n",
            "âœ“ Split is OK - empty count (739) is sufficient\n",
            "\n",
            "============================================================\n",
            "FINAL SPLIT COUNTS:\n",
            "============================================================\n",
            "split\n",
            "test_trans    23275\n",
            "test_cis      15827\n",
            "train         13133\n",
            "val_trans      2815\n",
            "val_cis        2814\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Binary labels:\n",
            "label_bin\n",
            "animal        51237\n",
            "non_animal     6627\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ultra-fast caching with optimizations\n",
        "import glob, hashlib\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import torch\n",
        "import os\n",
        "\n",
        "CACHE_DIR = \"/content/stage1_bin_cache_224\"\n",
        "os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "\n",
        "def cache_path(img_path):\n",
        "    return os.path.join(CACHE_DIR, hashlib.md5(img_path.encode()).hexdigest() + \".pt\")\n",
        "\n",
        "df[\"cache_path\"] = df[\"path\"].apply(cache_path)\n",
        "\n",
        "cached_count = len(glob.glob(CACHE_DIR + \"/*.pt\"))\n",
        "print(f\"âœ“ Cached tensors: {cached_count} / {len(df)}\")\n",
        "\n",
        "# Pre-compile transform (slight speed boost)\n",
        "pre_tf = T.Compose([\n",
        "    T.Resize((224, 224), antialias=True),  # antialias=True for quality\n",
        "    T.ToTensor(),\n",
        "])\n",
        "\n",
        "def process_one(row):\n",
        "    \"\"\"Optimized processing with early exit\"\"\"\n",
        "    cp = row[\"cache_path\"]\n",
        "    if os.path.exists(cp):\n",
        "        return\n",
        "    try:\n",
        "        # Use Image.open in a context manager (releases file handle faster)\n",
        "        with Image.open(row[\"path\"]) as img:\n",
        "            img_rgb = img.convert(\"RGB\")\n",
        "            x = pre_tf(img_rgb)\n",
        "        torch.save(x, cp)\n",
        "    except Exception:\n",
        "        pass  # Silently skip corrupted images\n",
        "\n",
        "if cached_count < len(df) * 0.95:\n",
        "    print(\"ðŸ”„ Caching tensors (8 workers)...\")\n",
        "\n",
        "    # Filter out already-cached rows BEFORE threading (faster)\n",
        "    rows_to_process = [row for _, row in df.iterrows() if not os.path.exists(row[\"cache_path\"])]\n",
        "\n",
        "    print(f\"   Processing {len(rows_to_process)} new images...\")\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=8) as ex:\n",
        "        list(tqdm(\n",
        "            ex.map(process_one, rows_to_process),\n",
        "            total=len(rows_to_process),\n",
        "            desc=\"Caching Stage1(bin)\"\n",
        "        ))\n",
        "\n",
        "    print(\"âœ“ Cache done:\", len(glob.glob(CACHE_DIR + \"/*.pt\")))\n",
        "else:\n",
        "    print(\"âœ“ Cache already exists âœ…\")\n",
        "\n",
        "# Keep only rows that have cache file (safety)\n",
        "df[\"has_cache\"] = df[\"cache_path\"].apply(os.path.exists)\n",
        "df = df[df[\"has_cache\"]].reset_index(drop=True)\n",
        "print(\"âœ“ Usable rows:\", len(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X-KI7nTu-Ia",
        "outputId": "0bc8b0dc-eedf-4559-fa24-7f66ad8d4dfb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Cached tensors: 57864 / 57864\n",
            "âœ“ Cache already exists âœ…\n",
            "âœ“ Usable rows: 57864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset + DataLoaders (balanced sampling + stable RAM)\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import torchvision.transforms as T\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "# label mapping (binary)\n",
        "classes = [\"animal\", \"non_animal\"]\n",
        "class_to_idx = {c:i for i,c in enumerate(classes)}\n",
        "idx_to_class = {i:c for c,i in class_to_idx.items()}\n",
        "df[\"y\"] = df[\"label_bin\"].map(class_to_idx)\n",
        "\n",
        "# splits\n",
        "train_df = df[df[\"split\"]==\"train\"].reset_index(drop=True)\n",
        "val_df   = df[df[\"split\"]==\"val_cis\"].reset_index(drop=True)\n",
        "valT_df  = df[df[\"split\"]==\"val_trans\"].reset_index(drop=True)\n",
        "test_cis_df   = df[df[\"split\"]==\"test_cis\"].reset_index(drop=True)\n",
        "test_trans_df = df[df[\"split\"]==\"test_trans\"].reset_index(drop=True)\n",
        "\n",
        "print(\"train:\", len(train_df), \"val_cis:\", len(val_df), \"val_trans:\", len(valT_df),\n",
        "      \"test_cis:\", len(test_cis_df), \"test_trans:\", len(test_trans_df))\n",
        "print(\"\\nTrain label counts:\\n\", train_df[\"label_bin\"].value_counts())\n",
        "\n",
        "# augmentation applied on tensor\n",
        "aug_tf = T.Compose([\n",
        "    T.RandomHorizontalFlip(0.5),\n",
        "    T.ColorJitter(0.2, 0.2, 0.1),\n",
        "])\n",
        "\n",
        "class CachedDS(Dataset):\n",
        "    def __init__(self, frame, augment=False):\n",
        "        self.df = frame.reset_index(drop=True)\n",
        "        self.augment = augment\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        r = self.df.iloc[i]\n",
        "        x = torch.load(r[\"cache_path\"])\n",
        "        if self.augment:\n",
        "            x = aug_tf(x)\n",
        "        y = int(r[\"y\"])\n",
        "        return x, y\n",
        "\n",
        "train_ds = CachedDS(train_df, augment=True)\n",
        "val_ds   = CachedDS(val_df, augment=False)\n",
        "valT_ds  = CachedDS(valT_df, augment=False)\n",
        "test_cis_ds   = CachedDS(test_cis_df, augment=False)\n",
        "test_trans_ds = CachedDS(test_trans_df, augment=False)\n",
        "\n",
        "# balanced sampler\n",
        "counts = train_df[\"y\"].value_counts().sort_index()\n",
        "w_class = 1.0 / counts\n",
        "w_sample = train_df[\"y\"].map(w_class).values\n",
        "sampler = WeightedRandomSampler(torch.tensor(w_sample, dtype=torch.double),\n",
        "                                num_samples=len(w_sample),\n",
        "                                replacement=True)\n",
        "\n",
        "# FIXED: class weights for loss (ensure it matches number of classes)\n",
        "class_weight = torch.ones(len(classes), dtype=torch.float32)  # Initialize for all classes\n",
        "\n",
        "for class_idx in counts.index:\n",
        "    class_weight[class_idx] = counts.sum() / (len(classes) * counts[class_idx])\n",
        "\n",
        "print(\"\\nCounts:\", counts.to_dict())\n",
        "print(\"Loss weights (shape={}):\", class_weight.shape, class_weight)\n",
        "\n",
        "# loaders\n",
        "BATCH_TRAIN = 32\n",
        "BATCH_EVAL  = 64\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_TRAIN, sampler=sampler,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds, batch_size=BATCH_EVAL, shuffle=False,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
        "valT_loader  = DataLoader(valT_ds, batch_size=BATCH_EVAL, shuffle=False,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
        "test_cis_loader = DataLoader(test_cis_ds, batch_size=BATCH_EVAL, shuffle=False,\n",
        "                             num_workers=NUM_WORKERS, pin_memory=True)\n",
        "test_trans_loader = DataLoader(test_trans_ds, batch_size=BATCH_EVAL, shuffle=False,\n",
        "                               num_workers=NUM_WORKERS, pin_memory=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P115Iseeu-Fk",
        "outputId": "4590632b-7bd9-4018-af42-3a75f494008f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: 13133 val_cis: 2814 val_trans: 2815 test_cis: 15827 test_trans: 23275\n",
            "\n",
            "Train label counts:\n",
            " label_bin\n",
            "animal        11898\n",
            "non_animal     1235\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Counts: {0: 11898, 1: 1235}\n",
            "Loss weights (shape={}): torch.Size([2]) tensor([0.5519, 5.3170])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train EfficientNet-B0 (binary) + save best to Drive\n",
        "import timm\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"âœ“ device:\", device)\n",
        "\n",
        "model = timm.create_model(\"efficientnet_b0\", pretrained=True, num_classes=len(classes)).to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weight.to(device))\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n",
        "ACCUM_STEPS = 2\n",
        "\n",
        "def eval_loader(loader, name=\"eval\"):\n",
        "    model.eval()\n",
        "    ys, ps = [], []\n",
        "    with torch.no_grad():\n",
        "        for x, y in tqdm(loader, desc=name, leave=False):\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "            with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
        "                logits = model(x)\n",
        "            p = logits.argmax(1)\n",
        "            ys.extend(y.cpu().tolist())\n",
        "            ps.extend(p.cpu().tolist())\n",
        "    acc = accuracy_score(ys, ps)\n",
        "    mf1 = f1_score(ys, ps, average=\"macro\")\n",
        "    return acc, mf1\n",
        "\n",
        "SAVE_PATH = f\"{PROC_DIR}/stage1_best_binary_efficientnet_b0.pt\"\n",
        "best = -1.0\n",
        "EPOCHS = 5\n",
        "\n",
        "for ep in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    running = 0.0\n",
        "\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {ep}/{EPOCHS} [train]\")\n",
        "    for i, (x, y) in enumerate(pbar, 1):\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        y = y.to(device, non_blocking=True)\n",
        "\n",
        "        with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y) / ACCUM_STEPS\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        if i % ACCUM_STEPS == 0:\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        running += loss.item() * x.size(0) * ACCUM_STEPS\n",
        "        pbar.set_postfix({\"loss\": f\"{loss.item()*ACCUM_STEPS:.4f}\"})\n",
        "\n",
        "    train_loss = running / len(train_df)\n",
        "\n",
        "    val_acc, val_mf1 = eval_loader(val_loader, \"val_cis\")\n",
        "    print(f\"\\nEpoch {ep}: train_loss={train_loss:.4f} | val_cis acc={val_acc:.3f} macroF1={val_mf1:.3f}\")\n",
        "\n",
        "    if len(valT_df) > 0:\n",
        "        vt_acc, vt_mf1 = eval_loader(valT_loader, \"val_trans\")\n",
        "        print(f\"          val_trans acc={vt_acc:.3f} macroF1={vt_mf1:.3f}\")\n",
        "\n",
        "    if val_mf1 > best:\n",
        "        best = val_mf1\n",
        "        torch.save(model.state_dict(), SAVE_PATH)\n",
        "        print(f\"ðŸ’¾ SAVED BEST â†’ {SAVE_PATH} (macroF1={best:.3f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKpG8O3Yu-C5",
        "outputId": "388f80e0-bc82-4705-ff23-435c5586b4ef"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4002588860.py:15: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n",
            "Epoch 1/5 [train]:   0%|          | 0/411 [00:00<?, ?it/s]/tmp/ipython-input-4002588860.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "Epoch 1/5 [train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 411/411 [01:24<00:00,  4.84it/s, loss=0.0285]\n",
            "val_cis:   0%|          | 0/44 [00:00<?, ?it/s]/tmp/ipython-input-4002588860.py:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: train_loss=0.3297 | val_cis acc=0.855 macroF1=0.738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val_trans:   0%|          | 0/44 [00:00<?, ?it/s]/tmp/ipython-input-4002588860.py:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_trans acc=0.837 macroF1=0.715\n",
            "ðŸ’¾ SAVED BEST â†’ /content/drive/MyDrive/datasets/cct20/processed/stage1_best_binary_efficientnet_b0.pt (macroF1=0.738)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5 [train]:   0%|          | 0/411 [00:00<?, ?it/s]/tmp/ipython-input-4002588860.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "Epoch 2/5 [train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 411/411 [01:04<00:00,  6.40it/s, loss=0.0551]\n",
            "val_cis:   0%|          | 0/44 [00:00<?, ?it/s]/tmp/ipython-input-4002588860.py:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2: train_loss=0.0702 | val_cis acc=0.877 macroF1=0.764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val_trans:   0%|          | 0/44 [00:00<?, ?it/s]/tmp/ipython-input-4002588860.py:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_trans acc=0.864 macroF1=0.743\n",
            "ðŸ’¾ SAVED BEST â†’ /content/drive/MyDrive/datasets/cct20/processed/stage1_best_binary_efficientnet_b0.pt (macroF1=0.764)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5 [train]:   0%|          | 0/411 [00:00<?, ?it/s]/tmp/ipython-input-4002588860.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "Epoch 3/5 [train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 411/411 [01:02<00:00,  6.57it/s, loss=0.0073]\n",
            "val_cis:   0%|          | 0/44 [00:00<?, ?it/s]/tmp/ipython-input-4002588860.py:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3: train_loss=0.0564 | val_cis acc=0.907 macroF1=0.805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val_trans:   0%|          | 0/44 [00:00<?, ?it/s]/tmp/ipython-input-4002588860.py:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_trans acc=0.894 macroF1=0.785\n",
            "ðŸ’¾ SAVED BEST â†’ /content/drive/MyDrive/datasets/cct20/processed/stage1_best_binary_efficientnet_b0.pt (macroF1=0.805)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5 [train]:   0%|          | 0/411 [00:00<?, ?it/s]/tmp/ipython-input-4002588860.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "Epoch 4/5 [train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 411/411 [01:02<00:00,  6.59it/s, loss=0.1732]\n",
            "val_cis:   0%|          | 0/44 [00:00<?, ?it/s]/tmp/ipython-input-4002588860.py:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4: train_loss=0.0367 | val_cis acc=0.927 macroF1=0.834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val_trans:   0%|          | 0/44 [00:00<?, ?it/s]/tmp/ipython-input-4002588860.py:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_trans acc=0.921 macroF1=0.825\n",
            "ðŸ’¾ SAVED BEST â†’ /content/drive/MyDrive/datasets/cct20/processed/stage1_best_binary_efficientnet_b0.pt (macroF1=0.834)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5 [train]:   0%|          | 0/411 [00:00<?, ?it/s]/tmp/ipython-input-4002588860.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "Epoch 5/5 [train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 411/411 [01:03<00:00,  6.49it/s, loss=0.0008]\n",
            "val_cis:   0%|          | 0/44 [00:00<?, ?it/s]/tmp/ipython-input-4002588860.py:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5: train_loss=0.0320 | val_cis acc=0.938 macroF1=0.854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val_trans:   0%|          | 0/44 [00:00<?, ?it/s]/tmp/ipython-input-4002588860.py:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_trans acc=0.930 macroF1=0.838\n",
            "ðŸ’¾ SAVED BEST â†’ /content/drive/MyDrive/datasets/cct20/processed/stage1_best_binary_efficientnet_b0.pt (macroF1=0.854)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Final test evaluation (CIS vs TRANS)\n",
        "from sklearn.metrics import classification_report\n",
        "import torch\n",
        "\n",
        "model.load_state_dict(torch.load(SAVE_PATH, map_location=device))\n",
        "\n",
        "def full_eval(loader, name=\"eval\"):\n",
        "    model.eval()\n",
        "    ys, ps = [], []\n",
        "    with torch.no_grad():\n",
        "        for x, y in tqdm(loader, desc=name):\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "            with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
        "                logits = model(x)\n",
        "            p = logits.argmax(1)\n",
        "            ys.extend(y.cpu().tolist())\n",
        "            ps.extend(p.cpu().tolist())\n",
        "    return ys, ps\n",
        "\n",
        "cis_y, cis_p = full_eval(test_cis_loader, \"test_cis\")\n",
        "tr_y,  tr_p  = full_eval(test_trans_loader, \"test_trans\")\n",
        "\n",
        "print(\"\\n--- CIS REPORT ---\")\n",
        "print(classification_report(cis_y, cis_p, target_names=classes))\n",
        "\n",
        "print(\"\\n--- TRANS REPORT ---\")\n",
        "print(classification_report(tr_y, tr_p, target_names=classes))\n"
      ],
      "metadata": {
        "id": "tPFKoapSu9_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e281d3f-7cb4-4121-a9d4-eb1122f6bcfa"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test_cis:   0%|          | 0/248 [00:00<?, ?it/s]/tmp/ipython-input-2556348763.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "test_cis: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 248/248 [01:14<00:00,  3.34it/s]\n",
            "test_trans: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 364/364 [01:46<00:00,  3.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- CIS REPORT ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      animal       0.96      0.89      0.93     13856\n",
            "  non_animal       0.50      0.77      0.61      1971\n",
            "\n",
            "    accuracy                           0.88     15827\n",
            "   macro avg       0.73      0.83      0.77     15827\n",
            "weighted avg       0.91      0.88      0.89     15827\n",
            "\n",
            "\n",
            "--- TRANS REPORT ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      animal       0.95      0.88      0.91     20384\n",
            "  non_animal       0.45      0.67      0.53      2891\n",
            "\n",
            "    accuracy                           0.86     23275\n",
            "   macro avg       0.70      0.78      0.72     23275\n",
            "weighted avg       0.89      0.86      0.87     23275\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save label mapping (Drive)\n",
        "import json\n",
        "\n",
        "mapping = {\"classes\": classes, \"class_to_idx\": class_to_idx}\n",
        "out_json = f\"{PROC_DIR}/stage1_binary_label_mapping.json\"\n",
        "with open(out_json, \"w\") as f:\n",
        "    json.dump(mapping, f, indent=2)\n",
        "\n",
        "print(\"âœ“ Saved:\", out_json)\n",
        "print(\"âœ“ Saved model:\", SAVE_PATH)\n"
      ],
      "metadata": {
        "id": "UldNRkFvu989",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a151773-a86e-4db0-be9a-4d582542a2e4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Saved: /content/drive/MyDrive/datasets/cct20/processed/stage1_binary_label_mapping.json\n",
            "âœ“ Saved model: /content/drive/MyDrive/datasets/cct20/processed/stage1_best_binary_efficientnet_b0.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_d30rI-L3c3K"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}