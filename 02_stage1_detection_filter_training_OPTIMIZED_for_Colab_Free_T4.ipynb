{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkse1yxVcW+i9fF3sxDa6a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "732d4b78ec7b445f964e79dd44eef880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15fc628e18d1442694f1c6934a579b2f",
              "IPY_MODEL_1d319471ac2c456ab476886d2fd09332",
              "IPY_MODEL_a4fbc04300294fd0800209fcc221e815"
            ],
            "layout": "IPY_MODEL_8573554df03841b787a14da9a0e86cc0"
          }
        },
        "15fc628e18d1442694f1c6934a579b2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_245a1ab45d414736853a14e1686e00be",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_42f613d21de24510b139812dc4d46934",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "1d319471ac2c456ab476886d2fd09332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_679269aa21b34441bd3d63dfb29ddce0",
            "max": 21355344,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0991fcb2f01a43eebcde3b4af7967828",
            "value": 21355344
          }
        },
        "a4fbc04300294fd0800209fcc221e815": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc51fddcef7a4aefb3532f19faa08f9f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a39f38ddd91a4babab14d2eb8efac1a6",
            "value": "‚Äá21.4M/21.4M‚Äá[00:00&lt;00:00,‚Äá726kB/s]"
          }
        },
        "8573554df03841b787a14da9a0e86cc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "245a1ab45d414736853a14e1686e00be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42f613d21de24510b139812dc4d46934": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "679269aa21b34441bd3d63dfb29ddce0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0991fcb2f01a43eebcde3b4af7967828": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc51fddcef7a4aefb3532f19faa08f9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a39f38ddd91a4babab14d2eb8efac1a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ErangaOttachchige/Final-Year-Research-Project/blob/main/02_stage1_detection_filter_training_OPTIMIZED_for_Colab_Free_T4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stage 1 Detection/Filter - ULTRA OPTIMIZED for Colab Free T4\n",
        "##\n",
        "### KEY OPTIMIZATIONS:\n",
        "### 1. Parallel caching with progress (8 workers)\n",
        "### 2. Reduced batch processing with gradient accumulation\n",
        "### 3. Smart worker config (no RAM crash)\n",
        "### 4. Optional: Skip caching, train directly from Drive (for smaller datasets)\n",
        "### 5. Memory-efficient data loading\n",
        "### 6. Faster evaluation"
      ],
      "metadata": {
        "id": "FbQL3LApQKut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stage 1 Binary Filter:\n",
        "\n",
        "Label: animal vs non_animal (where non_animal = empty + car)\n",
        "\n",
        "Fast: uses your tensor cache (no local copy, no Drive rsync)\n",
        "\n",
        "Stable: low RAM, no crashes\n",
        "\n",
        "Saves to Drive: model + label mapping\n",
        "\n",
        "Progress bars: train/val/test"
      ],
      "metadata": {
        "id": "Pk1LKCtzwDhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Drive + paths\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "import os\n",
        "DRIVE_CCT = \"/content/drive/MyDrive/datasets/cct20\"\n",
        "PROC_DIR  = f\"{DRIVE_CCT}/processed\"\n",
        "CSV_STAGE1 = f\"{PROC_DIR}/cct20_stage1_imagelevel.csv\"\n",
        "\n",
        "print(\"‚úì PROC_DIR files:\", os.listdir(PROC_DIR))\n",
        "print(\"‚úì Stage1 CSV exists:\", os.path.exists(CSV_STAGE1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ASBJIXTRCU5",
        "outputId": "eb333afe-45ee-4fff-f52a-57b2eaf35e6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úì PROC_DIR files: ['cct20_species_annotations.csv', 'cct20_stage1_imagelevel.csv', 'cct20_stage2_species_imagelevel.csv', 'stage2_best_species_efficientnet_b0_optimized.pt', 'stage2_label_mapping.json', 'stage1_best_efficientnet_b0.pt', 'stage1_label_mapping.json', 'stage1_best_binary_efficientnet_b0.pt', 'stage1_binary_label_mapping.json']\n",
            "‚úì Stage1 CSV exists: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install packages + check GPU\n",
        "!pip -q install timm torchmetrics pandas numpy scikit-learn pillow tqdm\n",
        "\n",
        "import torch\n",
        "print(\"‚úì CUDA:\", torch.cuda.is_available())\n",
        "print(\"‚úì GPU :\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fu01OM00u-Nq",
        "outputId": "411c5ce0-6d7e-40a0-98df-9238b2f721f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/983.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m983.0/983.2 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h‚úì CUDA: True\n",
            "‚úì GPU : Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Stage1 CSV + create binary labels\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "df = pd.read_csv(CSV_STAGE1)\n",
        "\n",
        "# Binary label:\n",
        "# animal stays animal\n",
        "# car + empty become non_animal\n",
        "df[\"label_bin\"] = df[\"label_stage1\"].apply(lambda x: \"animal\" if x==\"animal\" else \"non_animal\")\n",
        "\n",
        "missing = (~df[\"path\"].apply(os.path.exists)).sum()\n",
        "print(f\"‚úì Rows: {len(df)}, Missing paths: {missing}\")\n",
        "print(\"\\nSplit counts:\\n\", df[\"split\"].value_counts())\n",
        "print(\"\\nBinary label counts:\\n\", df[\"label_bin\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uOToepCu-K6",
        "outputId": "42b7c7e1-3ae2-4071-96cd-1e007abec64f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Rows: 57864, Missing paths: 1\n",
            "\n",
            "Split counts:\n",
            " split\n",
            "test_trans    23275\n",
            "test_cis      15827\n",
            "train         13553\n",
            "val_cis        3484\n",
            "val_trans      1725\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Binary label counts:\n",
            " label_bin\n",
            "animal        51237\n",
            "non_animal     6627\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ultra-fast caching with optimizations\n",
        "import glob, hashlib\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import torch\n",
        "import os\n",
        "\n",
        "CACHE_DIR = \"/content/stage1_bin_cache_224\"\n",
        "os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "\n",
        "def cache_path(img_path):\n",
        "    return os.path.join(CACHE_DIR, hashlib.md5(img_path.encode()).hexdigest() + \".pt\")\n",
        "\n",
        "df[\"cache_path\"] = df[\"path\"].apply(cache_path)\n",
        "\n",
        "cached_count = len(glob.glob(CACHE_DIR + \"/*.pt\"))\n",
        "print(f\"‚úì Cached tensors: {cached_count} / {len(df)}\")\n",
        "\n",
        "# Pre-compile transform (slight speed boost)\n",
        "pre_tf = T.Compose([\n",
        "    T.Resize((224, 224), antialias=True),  # antialias=True for quality\n",
        "    T.ToTensor(),\n",
        "])\n",
        "\n",
        "def process_one(row):\n",
        "    \"\"\"Optimized processing with early exit\"\"\"\n",
        "    cp = row[\"cache_path\"]\n",
        "    if os.path.exists(cp):\n",
        "        return\n",
        "    try:\n",
        "        # Use Image.open in a context manager (releases file handle faster)\n",
        "        with Image.open(row[\"path\"]) as img:\n",
        "            img_rgb = img.convert(\"RGB\")\n",
        "            x = pre_tf(img_rgb)\n",
        "        torch.save(x, cp)\n",
        "    except Exception:\n",
        "        pass  # Silently skip corrupted images\n",
        "\n",
        "if cached_count < len(df) * 0.95:\n",
        "    print(\"üîÑ Caching tensors (8 workers)...\")\n",
        "\n",
        "    # Filter out already-cached rows BEFORE threading (faster)\n",
        "    rows_to_process = [row for _, row in df.iterrows() if not os.path.exists(row[\"cache_path\"])]\n",
        "\n",
        "    print(f\"   Processing {len(rows_to_process)} new images...\")\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=8) as ex:\n",
        "        list(tqdm(\n",
        "            ex.map(process_one, rows_to_process),\n",
        "            total=len(rows_to_process),\n",
        "            desc=\"Caching Stage1(bin)\"\n",
        "        ))\n",
        "\n",
        "    print(\"‚úì Cache done:\", len(glob.glob(CACHE_DIR + \"/*.pt\")))\n",
        "else:\n",
        "    print(\"‚úì Cache already exists ‚úÖ\")\n",
        "\n",
        "# Keep only rows that have cache file (safety)\n",
        "df[\"has_cache\"] = df[\"cache_path\"].apply(os.path.exists)\n",
        "df = df[df[\"has_cache\"]].reset_index(drop=True)\n",
        "print(\"‚úì Usable rows:\", len(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X-KI7nTu-Ia",
        "outputId": "f0407b0e-3f9e-4eae-8242-8bf14bf28490"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Cached tensors: 0 / 57864\n",
            "üîÑ Caching tensors (8 workers)...\n",
            "   Processing 57864 new images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Caching Stage1(bin): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57864/57864 [50:16<00:00, 19.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Cache done: 57864\n",
            "‚úì Usable rows: 57864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset + DataLoaders (balanced sampling + stable RAM)\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import torchvision.transforms as T\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "# label mapping (binary)\n",
        "classes = [\"animal\", \"non_animal\"]\n",
        "class_to_idx = {c:i for i,c in enumerate(classes)}\n",
        "idx_to_class = {i:c for c,i in class_to_idx.items()}\n",
        "df[\"y\"] = df[\"label_bin\"].map(class_to_idx)\n",
        "\n",
        "# splits\n",
        "train_df = df[df[\"split\"]==\"train\"].reset_index(drop=True)\n",
        "val_df   = df[df[\"split\"]==\"val_cis\"].reset_index(drop=True)\n",
        "valT_df  = df[df[\"split\"]==\"val_trans\"].reset_index(drop=True)\n",
        "test_cis_df   = df[df[\"split\"]==\"test_cis\"].reset_index(drop=True)\n",
        "test_trans_df = df[df[\"split\"]==\"test_trans\"].reset_index(drop=True)\n",
        "\n",
        "print(\"train:\", len(train_df), \"val_cis:\", len(val_df), \"val_trans:\", len(valT_df),\n",
        "      \"test_cis:\", len(test_cis_df), \"test_trans:\", len(test_trans_df))\n",
        "print(\"\\nTrain label counts:\\n\", train_df[\"label_bin\"].value_counts())\n",
        "\n",
        "# augmentation applied on tensor\n",
        "aug_tf = T.Compose([\n",
        "    T.RandomHorizontalFlip(0.5),\n",
        "    T.ColorJitter(0.2, 0.2, 0.1),\n",
        "])\n",
        "\n",
        "class CachedDS(Dataset):\n",
        "    def __init__(self, frame, augment=False):\n",
        "        self.df = frame.reset_index(drop=True)\n",
        "        self.augment = augment\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        r = self.df.iloc[i]\n",
        "        x = torch.load(r[\"cache_path\"])\n",
        "        if self.augment:\n",
        "            x = aug_tf(x)\n",
        "        y = int(r[\"y\"])\n",
        "        return x, y\n",
        "\n",
        "train_ds = CachedDS(train_df, augment=True)\n",
        "val_ds   = CachedDS(val_df, augment=False)\n",
        "valT_ds  = CachedDS(valT_df, augment=False)\n",
        "test_cis_ds   = CachedDS(test_cis_df, augment=False)\n",
        "test_trans_ds = CachedDS(test_trans_df, augment=False)\n",
        "\n",
        "# balanced sampler\n",
        "counts = train_df[\"y\"].value_counts().sort_index()\n",
        "w_class = 1.0 / counts\n",
        "w_sample = train_df[\"y\"].map(w_class).values\n",
        "sampler = WeightedRandomSampler(torch.tensor(w_sample, dtype=torch.double),\n",
        "                                num_samples=len(w_sample),\n",
        "                                replacement=True)\n",
        "\n",
        "# class weights for loss (binary)\n",
        "cw = (counts.sum() / (len(classes) * counts)).values\n",
        "class_weight = torch.tensor(cw, dtype=torch.float32)\n",
        "print(\"\\nCounts:\", counts.to_dict())\n",
        "print(\"Loss weights:\", class_weight)\n",
        "\n",
        "# loaders\n",
        "BATCH_TRAIN = 32\n",
        "BATCH_EVAL  = 64\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_TRAIN, sampler=sampler,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds, batch_size=BATCH_EVAL, shuffle=False,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
        "valT_loader  = DataLoader(valT_ds, batch_size=BATCH_EVAL, shuffle=False,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
        "test_cis_loader = DataLoader(test_cis_ds, batch_size=BATCH_EVAL, shuffle=False,\n",
        "                             num_workers=NUM_WORKERS, pin_memory=True)\n",
        "test_trans_loader = DataLoader(test_trans_ds, batch_size=BATCH_EVAL, shuffle=False,\n",
        "                               num_workers=NUM_WORKERS, pin_memory=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P115Iseeu-Fk",
        "outputId": "5ae1a923-30ee-4624-b2a8-ecbe6625dbe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: 13553 val_cis: 3484 val_trans: 1725 test_cis: 15827 test_trans: 23275\n",
            "\n",
            "Train label counts:\n",
            " label_bin\n",
            "animal        12885\n",
            "non_animal      668\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Counts: {0: 12885, 1: 668}\n",
            "Loss weights: tensor([ 0.5259, 10.1445])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train EfficientNet-B0 (binary) + save best to Drive\n",
        "import timm\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"‚úì device:\", device)\n",
        "\n",
        "model = timm.create_model(\"efficientnet_b0\", pretrained=True, num_classes=len(classes)).to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weight.to(device))\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n",
        "ACCUM_STEPS = 2\n",
        "\n",
        "def eval_loader(loader, name=\"eval\"):\n",
        "    model.eval()\n",
        "    ys, ps = [], []\n",
        "    with torch.no_grad():\n",
        "        for x, y in tqdm(loader, desc=name, leave=False):\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "            with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
        "                logits = model(x)\n",
        "            p = logits.argmax(1)\n",
        "            ys.extend(y.cpu().tolist())\n",
        "            ps.extend(p.cpu().tolist())\n",
        "    acc = accuracy_score(ys, ps)\n",
        "    mf1 = f1_score(ys, ps, average=\"macro\")\n",
        "    return acc, mf1\n",
        "\n",
        "SAVE_PATH = f\"{PROC_DIR}/stage1_best_binary_efficientnet_b0.pt\"\n",
        "best = -1.0\n",
        "EPOCHS = 5\n",
        "\n",
        "for ep in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    running = 0.0\n",
        "\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {ep}/{EPOCHS} [train]\")\n",
        "    for i, (x, y) in enumerate(pbar, 1):\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        y = y.to(device, non_blocking=True)\n",
        "\n",
        "        with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y) / ACCUM_STEPS\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        if i % ACCUM_STEPS == 0:\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        running += loss.item() * x.size(0) * ACCUM_STEPS\n",
        "        pbar.set_postfix({\"loss\": f\"{loss.item()*ACCUM_STEPS:.4f}\"})\n",
        "\n",
        "    train_loss = running / len(train_df)\n",
        "\n",
        "    val_acc, val_mf1 = eval_loader(val_loader, \"val_cis\")\n",
        "    print(f\"\\nEpoch {ep}: train_loss={train_loss:.4f} | val_cis acc={val_acc:.3f} macroF1={val_mf1:.3f}\")\n",
        "\n",
        "    if len(valT_df) > 0:\n",
        "        vt_acc, vt_mf1 = eval_loader(valT_loader, \"val_trans\")\n",
        "        print(f\"          val_trans acc={vt_acc:.3f} macroF1={vt_mf1:.3f}\")\n",
        "\n",
        "    if val_mf1 > best:\n",
        "        best = val_mf1\n",
        "        torch.save(model.state_dict(), SAVE_PATH)\n",
        "        print(f\"üíæ SAVED BEST ‚Üí {SAVE_PATH} (macroF1={best:.3f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "732d4b78ec7b445f964e79dd44eef880",
            "15fc628e18d1442694f1c6934a579b2f",
            "1d319471ac2c456ab476886d2fd09332",
            "a4fbc04300294fd0800209fcc221e815",
            "8573554df03841b787a14da9a0e86cc0",
            "245a1ab45d414736853a14e1686e00be",
            "42f613d21de24510b139812dc4d46934",
            "679269aa21b34441bd3d63dfb29ddce0",
            "0991fcb2f01a43eebcde3b4af7967828",
            "dc51fddcef7a4aefb3532f19faa08f9f",
            "a39f38ddd91a4babab14d2eb8efac1a6"
          ]
        },
        "id": "GKpG8O3Yu-C5",
        "outputId": "07167817-b018-4d1d-f011-74e54b19c2c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/21.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "732d4b78ec7b445f964e79dd44eef880"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4002588860.py:15: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n",
            "Epoch 1/5 [train]:   0%|          | 0/424 [00:00<?, ?it/s]/tmp/ipython-input-4002588860.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "Epoch 1/5 [train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 424/424 [01:33<00:00,  4.53it/s, loss=0.0000]\n",
            "val_cis:   0%|          | 0/55 [00:00<?, ?it/s]/tmp/ipython-input-4002588860.py:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: train_loss=0.0371 | val_cis acc=0.726 macroF1=0.495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val_trans:   0%|          | 0/27 [00:00<?, ?it/s]/tmp/ipython-input-4002588860.py:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_trans acc=0.963 macroF1=0.559\n",
            "üíæ SAVED BEST ‚Üí /content/drive/MyDrive/datasets/cct20/processed/stage1_best_binary_efficientnet_b0.pt (macroF1=0.495)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/5 [train]:   0%|          | 0/424 [00:00<?, ?it/s]/tmp/ipython-input-4002588860.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "Epoch 2/5 [train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 424/424 [01:07<00:00,  6.27it/s, loss=0.0000]\n",
            "val_cis:   0%|          | 0/55 [00:00<?, ?it/s]/tmp/ipython-input-4002588860.py:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2: train_loss=0.0023 | val_cis acc=0.721 macroF1=0.477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val_trans:   0%|          | 0/27 [00:00<?, ?it/s]/tmp/ipython-input-4002588860.py:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_trans acc=0.901 macroF1=0.540\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5 [train]:   0%|          | 0/424 [00:00<?, ?it/s]/tmp/ipython-input-4002588860.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "Epoch 3/5 [train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 424/424 [01:11<00:00,  5.96it/s, loss=0.0000]\n",
            "val_cis:   0%|          | 0/55 [00:00<?, ?it/s]/tmp/ipython-input-4002588860.py:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3: train_loss=0.0023 | val_cis acc=0.725 macroF1=0.490\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val_trans:   0%|          | 0/27 [00:00<?, ?it/s]/tmp/ipython-input-4002588860.py:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_trans acc=0.835 macroF1=0.499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5 [train]:   0%|          | 0/424 [00:00<?, ?it/s]/tmp/ipython-input-4002588860.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "Epoch 4/5 [train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 424/424 [01:02<00:00,  6.77it/s, loss=0.1304]\n",
            "val_cis:   0%|          | 0/55 [00:00<?, ?it/s]/tmp/ipython-input-4002588860.py:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4: train_loss=0.0032 | val_cis acc=0.714 macroF1=0.456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val_trans:   0%|          | 0/27 [00:00<?, ?it/s]/tmp/ipython-input-4002588860.py:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_trans acc=0.961 macroF1=0.490\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5 [train]:   0%|          | 0/424 [00:00<?, ?it/s]/tmp/ipython-input-4002588860.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "Epoch 5/5 [train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 424/424 [01:02<00:00,  6.75it/s, loss=0.0000]\n",
            "val_cis:   0%|          | 0/55 [00:00<?, ?it/s]/tmp/ipython-input-4002588860.py:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5: train_loss=0.0043 | val_cis acc=0.716 macroF1=0.459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val_trans:   0%|          | 0/27 [00:00<?, ?it/s]/tmp/ipython-input-4002588860.py:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          val_trans acc=0.965 macroF1=0.507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Final test evaluation (CIS vs TRANS)\n",
        "from sklearn.metrics import classification_report\n",
        "import torch\n",
        "\n",
        "model.load_state_dict(torch.load(SAVE_PATH, map_location=device))\n",
        "\n",
        "def full_eval(loader, name=\"eval\"):\n",
        "    model.eval()\n",
        "    ys, ps = [], []\n",
        "    with torch.no_grad():\n",
        "        for x, y in tqdm(loader, desc=name):\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "            with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
        "                logits = model(x)\n",
        "            p = logits.argmax(1)\n",
        "            ys.extend(y.cpu().tolist())\n",
        "            ps.extend(p.cpu().tolist())\n",
        "    return ys, ps\n",
        "\n",
        "cis_y, cis_p = full_eval(test_cis_loader, \"test_cis\")\n",
        "tr_y,  tr_p  = full_eval(test_trans_loader, \"test_trans\")\n",
        "\n",
        "print(\"\\n--- CIS REPORT ---\")\n",
        "print(classification_report(cis_y, cis_p, target_names=classes))\n",
        "\n",
        "print(\"\\n--- TRANS REPORT ---\")\n",
        "print(classification_report(tr_y, tr_p, target_names=classes))\n"
      ],
      "metadata": {
        "id": "tPFKoapSu9_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08ec30ce-626a-4c05-ed25-b18686f2ed32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test_cis:   0%|          | 0/248 [00:00<?, ?it/s]/tmp/ipython-input-2556348763.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "test_cis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 248/248 [01:19<00:00,  3.14it/s]\n",
            "test_trans: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 364/364 [01:54<00:00,  3.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- CIS REPORT ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      animal       0.93      1.00      0.96     13856\n",
            "  non_animal       0.95      0.43      0.59      1971\n",
            "\n",
            "    accuracy                           0.93     15827\n",
            "   macro avg       0.94      0.71      0.78     15827\n",
            "weighted avg       0.93      0.93      0.91     15827\n",
            "\n",
            "\n",
            "--- TRANS REPORT ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      animal       0.92      0.98      0.95     20384\n",
            "  non_animal       0.74      0.43      0.54      2891\n",
            "\n",
            "    accuracy                           0.91     23275\n",
            "   macro avg       0.83      0.70      0.75     23275\n",
            "weighted avg       0.90      0.91      0.90     23275\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save label mapping (Drive)\n",
        "import json\n",
        "\n",
        "mapping = {\"classes\": classes, \"class_to_idx\": class_to_idx}\n",
        "out_json = f\"{PROC_DIR}/stage1_binary_label_mapping.json\"\n",
        "with open(out_json, \"w\") as f:\n",
        "    json.dump(mapping, f, indent=2)\n",
        "\n",
        "print(\"‚úì Saved:\", out_json)\n",
        "print(\"‚úì Saved model:\", SAVE_PATH)\n"
      ],
      "metadata": {
        "id": "UldNRkFvu989",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aacc01d3-f963-4430-f69e-dbd2f834a60d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Saved: /content/drive/MyDrive/datasets/cct20/processed/stage1_binary_label_mapping.json\n",
            "‚úì Saved model: /content/drive/MyDrive/datasets/cct20/processed/stage1_best_binary_efficientnet_b0.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bvbv_fF3LKoa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}